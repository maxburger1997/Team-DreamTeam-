{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a4f57f",
   "metadata": {
    "id": "e2a4f57f"
   },
   "source": [
    "# Machine Learning Project 2022: Plankton\n",
    "\n",
    "### Authors:\n",
    "- Bram Fresen\n",
    "- Bram Huis\n",
    "- Max Burger\n",
    "- Moos Middelkoop\n",
    "\n",
    "For the Machine Learning Project to finish off the minor Artificial Intelligence, we chose to tackle the plankton problem, originally uploaded as the United States national data science bowl in december 2014. For this problem, the goal is to classify microscopic images of particles in water as one of 121 different classes of plankton. The dataset is 30.000 images large, with varying sizes. The dataset is also imbalanced.\n",
    "\n",
    "In order to solve this problem we will make use of a Convolutional Neural Network using the tensorflow library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144121",
   "metadata": {
    "id": "fb144121"
   },
   "source": [
    "## Import libraries\n",
    "\n",
    "Firstly, we will import the needed libraries, and check if we are running on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8cd45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccc8cd45",
    "outputId": "5ceaf3a6-89a3-4132-b874-2056369f237b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80ec50",
   "metadata": {
    "id": "0d80ec50"
   },
   "source": [
    "## Loading the training data, training labels and test data\n",
    "\n",
    "We use the cv2 library to load the training images (which are .jpg files), and turn them into arrays. This piece of code was found online:\n",
    "\n",
    "https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "https://drive.google.com/file/d/1hAaPzDMVEZ8X1tfRS2ieFEqi0R7Ww7uL/view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaee28b",
   "metadata": {
    "id": "0eaee28b"
   },
   "source": [
    "### Test data\n",
    "\n",
    "The test data is unlabeled, so we can't use it for our own training, we can only try to predict the classes and submit our solution to kaggle to see how we did. We will probably not use this data much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bcd22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "8c6bcd22",
    "outputId": "396299cd-19df-4d48-8d14-3b8f2aacefe1"
   },
   "outputs": [],
   "source": [
    "# Create an empty list for the test data\n",
    "test_data = []\n",
    "\n",
    "# Path to folder for the test data\n",
    "folder_test = 'data/test'\n",
    "\n",
    "# Loop through the images, read them in and add them to a list\n",
    "for image in os.listdir(folder_test):\n",
    "    img = cv2.imread(os.path.join(folder_test, image))\n",
    "    test_data.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851be41",
   "metadata": {
    "id": "c851be41"
   },
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ae544",
   "metadata": {
    "id": "024ae544"
   },
   "outputs": [],
   "source": [
    "# Create empty lists for the not resized training data and then labels (not one hot encoded yet)\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "# Create a folder path of the different categories\n",
    "folder_train = 'data/train'\n",
    "\n",
    "# Loop through the index (for the one hot matrix) and the categories\n",
    "for number, categories in enumerate(os.listdir(folder_train)):\n",
    "    \n",
    "    # Loop through the images , read them in and add them to a list, also add the index 'number' to \n",
    "    # a list for the one hot matrix\n",
    "    for image in os.listdir(f'data/train/{categories}'):\n",
    "        train_labels.append(number)\n",
    "        img = cv2.imread(os.path.join(f'data/train/{categories}', image))\n",
    "        train_data.append(img)\n",
    "\n",
    "# Create a one hot matrix from the train labels\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0704a",
   "metadata": {
    "id": "89a0704a"
   },
   "source": [
    "There are 3 channels in each of the images. The cell below shows that each of the channels have the same values (test 1 and 2). Test 3 and 4 are here to show that the 'np.array_equal' function works; the values from different images return a false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9048ef",
   "metadata": {
    "id": "2b9048ef",
    "outputId": "8b5b04c2-5173-4bed-919f-2c60161f030c"
   },
   "outputs": [],
   "source": [
    "x = train_data[0]\n",
    "y = train_data[1]\n",
    "\n",
    "a0 = x[:, :, 0]\n",
    "b0 = x[:, :, 1]\n",
    "c0 = x[:, :, 2]\n",
    "\n",
    "a1 = y[:, :, 0]\n",
    "b1 = y[:, :, 1]\n",
    "c1 = y[:, :, 2]\n",
    "\n",
    "test_1 = np.array_equal(a0, b0)\n",
    "test_2 = np.array_equal(b0, c0)\n",
    "\n",
    "test_3 = np.array_equal(a0, a1)\n",
    "test_4 = np.array_equal(b0, c1)\n",
    "\n",
    "\n",
    "print(f' Test 1: {test_1}, Test 2: {test_2}')\n",
    "print(f' Test 3: {test_3}, Test 4: {test_4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GXoidNUu9Crm",
   "metadata": {
    "id": "GXoidNUu9Crm"
   },
   "source": [
    "### Delete unnecessary channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qaI7P5qy9L3Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "qaI7P5qy9L3Q",
    "outputId": "7552739a-b447-4b3d-ea37-22a6185e540f"
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(train_data):\n",
    "  train_data[i] = image[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d208c",
   "metadata": {
    "id": "1d7d208c"
   },
   "source": [
    "# Resize input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838d255",
   "metadata": {
    "id": "5838d255",
    "outputId": "333e4faa-c45c-4ba3-e9a6-9943bfa2e55d"
   },
   "outputs": [],
   "source": [
    "# Start with an infinitely large number\n",
    "value_1 = math.inf\n",
    "value_2 = math.inf\n",
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "count = 0\n",
    "\n",
    "# This checks for the lowest image size in the first and second dimension\n",
    "for image in train_data:\n",
    "    count+=1\n",
    "    sum_1 += image.shape[0]\n",
    "    sum_2 += image.shape[1]\n",
    "    if image.shape[0] < value_1:\n",
    "        \n",
    "        value_1 = image.shape[0]\n",
    "        hold_1 = image.shape\n",
    "    if image.shape[1] < value_2:\n",
    "        \n",
    "        value_2 = image.shape[0]\n",
    "        hold_2 = image.shape\n",
    "        \n",
    "sum_11 = sum_1 / count\n",
    "sum_22 = sum_2 / count\n",
    "\n",
    "print(f'Average dimensions: {sum_11}, {sum_22}')\n",
    "\n",
    "plt.imshow(train_data[0])\n",
    "\n",
    "print(f'Lowest first dimension image {hold_1}')\n",
    "print(f'Lowest second dimension image {hold_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a2aa4",
   "metadata": {
    "id": "ff1a2aa4",
    "outputId": "150a5232-50fb-47e4-f6d5-18b8b06b0f37"
   },
   "outputs": [],
   "source": [
    "# Create an empty list for the training data\n",
    "train_data_resized = []\n",
    "\n",
    "# Loop through the images in the training data and resize them to the lowest shape in the dataset, \n",
    "# then append the image to the 'train_data_resized' list\n",
    "for image in train_data:\n",
    "    img = cv2.resize(image, (28, 28))\n",
    "    train_data_resized.append(img)\n",
    "\n",
    "# Test if the image is resized and show the image\n",
    "print(train_data_resized[0].shape)\n",
    "plt.imshow(train_data_resized[0])\n",
    "\n",
    "#Split the data into 70% training and 30% validation\n",
    "im_train, im_val, lab_train, lab_val = train_test_split(train_data_resized, train_labels_one_hot, train_size=0.7, random_state=1265599650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddaa21",
   "metadata": {
    "id": "9cddaa21",
    "outputId": "c51e8555-94fe-470f-9215-84e3d0d2ab4f"
   },
   "outputs": [],
   "source": [
    "# Convert the data to numpy arrays, so tensorflow can use them\n",
    "image_train = np.array(im_train)\n",
    "label_train = np.array(lab_train)\n",
    "image_val = np.array(im_val)\n",
    "label_val = np.array(lab_val)\n",
    "\n",
    "# Test if the shapes are correct\n",
    "print(image_train.shape)\n",
    "print(label_train.shape)\n",
    "print(image_val.shape)\n",
    "print(label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024880",
   "metadata": {
    "id": "15024880"
   },
   "source": [
    "## Convolutional network\n",
    "\n",
    "We use the function 'train_and_evaluate' which, obviously, trains our model and then evaluates the trained model on the validation data. This function was reused from the CIFAR-assignment from module 6 of ML2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49593d",
   "metadata": {
    "id": "3b49593d"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_x, train_y, val_x, val_y, preprocess={}, epochs=20, augment={}):\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
    "    train_gen.fit(train_x) \n",
    "\n",
    "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
    "    val_gen.fit(train_x)\n",
    "\n",
    "    history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n",
    "                        validation_data=val_gen.flow(val_x, val_y))\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
    "\n",
    "    for i, metric in enumerate(['loss', 'accuracy']):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].plot(history.history['val_'+metric])\n",
    "        axs[i].legend(['training', 'validation'], loc='best')\n",
    "\n",
    "        axs[i].set_title('Model '+metric)\n",
    "        axs[i].set_ylabel(metric)\n",
    "        axs[i].set_xlabel('epoch')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Validation Accuracy: {model.evaluate(val_gen.flow(val_x, val_y))[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2820be",
   "metadata": {
    "id": "3c2820be"
   },
   "source": [
    "## The actual model\n",
    "\n",
    "We start with a very simple convolutional neural network, with 2 convolutional layers, both with pooling afterwards, and one dense layer. kernelsize, amount of filters, amount of nodes are specified in the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f63f17",
   "metadata": {
    "id": "54f63f17",
    "outputId": "95b5f3dc-8354-4a8e-e4e0-4e0d7e9642bf"
   },
   "outputs": [],
   "source": [
    "first_layer_filters = 32\n",
    "second_layer_filters = 64\n",
    "kernelsize = (3,3)\n",
    "inputshape = (28,28,3)\n",
    "first_hidden_layer_nodes = 128\n",
    "output_nodes = 121\n",
    "\n",
    "model_1 = models.Sequential()\n",
    "\n",
    "model_1.add(layers.Conv2D(first_layer_filters, kernelsize, activation = 'relu', padding = 'same', input_shape = inputshape))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(second_layer_filters, kernelsize, activation = 'relu', padding = 'same', input_shape = inputshape))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(first_hidden_layer_nodes, activation = 'relu'))\n",
    "model_1.add(layers.Dense(output_nodes, activation = 'softmax'))\n",
    "\n",
    "train_and_evaluate(model_1, image_train, label_train, image_val, label_val, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d7c81",
   "metadata": {
    "id": "fc7d7c81"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Plankton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
