{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a4f57f",
   "metadata": {
    "id": "e2a4f57f"
   },
   "source": [
    "# Machine Learning Project 2022: Plankton\n",
    "\n",
    "### Authors:\n",
    "- Bram Fresen\n",
    "- Bram Huis\n",
    "- Max Burger\n",
    "- Moos Middelkoop\n",
    "\n",
    "For the Machine Learning Project to finish off the minor Artificial Intelligence, we chose to tackle the plankton problem, originally uploaded as the United States national data science bowl in december 2014. For this problem, the goal is to classify microscopic images of particles in water as one of 121 different classes of plankton. The dataset is 30.000 images large, with varying sizes. The dataset is also imbalanced.\n",
    "\n",
    "In order to solve this problem we will make use of a Convolutional Neural Network using the tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sNNILgDqcVuS",
   "metadata": {
    "id": "sNNILgDqcVuS"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144121",
   "metadata": {
    "id": "fb144121"
   },
   "source": [
    "## Import libraries\n",
    "\n",
    "Firstly, we will import the needed libraries, and check if we are running on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc8cd45",
   "metadata": {
    "id": "ccc8cd45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow import math as tfmath\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80ec50",
   "metadata": {
    "id": "0d80ec50"
   },
   "source": [
    "## Loading the training data and training labels\n",
    "\n",
    "We use the cv2 library to load the training images (which are .jpg files), and turn them into arrays. This piece of code was found online:\n",
    "\n",
    "https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "https://drive.google.com/file/d/1hAaPzDMVEZ8X1tfRS2ieFEqi0R7Ww7uL/view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851be41",
   "metadata": {
    "id": "c851be41"
   },
   "source": [
    "### Training data\n",
    "\n",
    "Training data is sorted into folders by class, this next piece of code reads in the training data, puts it in an array, and constructs an array for the classes by using the names of the folders. At the end, this array for the labels is turned into a one-hot matrix, so that tensorflow can work with it.\n",
    "\n",
    "We also delete the unnecessary channels here already, all input images consist of 3 channels with exactly the same values, so we drop two of them in order to remove redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024ae544",
   "metadata": {
    "id": "024ae544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "def read_data(folder):\n",
    "    # Create empty lists for the not resized training data, the labels (not one hot encoded yet) and the class sizes\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    class_size_list = []\n",
    "    categories_list =[]\n",
    "    offset = 0\n",
    "\n",
    "    # Loop through the index (for the one hot matrix) and the categories\n",
    "    for number, categories in enumerate(os.listdir(folder)):\n",
    "        class_size = 0\n",
    "        categories_list.append(categories)\n",
    "        print(number)\n",
    "\n",
    "        # If we come across a hidden folder (starting with \".\") on mac os, we ignore it\n",
    "        if categories[0] == \".\":\n",
    "            offset += 1\n",
    "            continue\n",
    "\n",
    "        # Loop through the images , add 1 to the class size, read the images in in and add them to a list, \n",
    "        # also add the index 'number' to a list for the one hot matrix\n",
    "        for image in os.listdir(f'{folder}/{categories}'):\n",
    "            class_size += 1\n",
    "            train_labels.append(number - offset)\n",
    "            img = cv2.imread(os.path.join(f'{folder}/{categories}', image))\n",
    "            train_data.append(img[:, :, 0])\n",
    "      \n",
    "        # Append the size of the class to the class size list, in order to check the class sizes later, this way we\n",
    "        # can ananlyze the degree of class imbalance\n",
    "        class_size_list.append(class_size)\n",
    "\n",
    "    # Create a one hot matrix from the train labels\n",
    "    train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=121)\n",
    "  \n",
    "    return train_data, train_labels_one_hot, class_size_list, categories_list\n",
    "\n",
    "train_data, train_labels, class_size_list, categories_list = read_data('data/train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d208c",
   "metadata": {
    "id": "1d7d208c"
   },
   "source": [
    "# Resize input images\n",
    "\n",
    "Because all images are differnt sizes, it is necessary to resize all input data to the same size, in order to make tensorflow be able to work with the data. The first cell below analyzes the sizes of the data, and the second cell actually resizes, based on this analysis. An essential element is explicitly adding a third dimension with a value of 1 to the images, otherwise tensorflow can't work with the data. Lastly, the data is converted into numpy arrays, so tensorflow will be able to work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5838d255",
   "metadata": {
    "id": "5838d255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average dimensions: 66.66182093881856, 73.50728507383967\n",
      "Lowest first dimension image (21, 71)\n",
      "Lowest second dimension image (31, 49)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start with an infinitely large number\n",
    "value_1 = math.inf\n",
    "value_2 = math.inf\n",
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "count = 0\n",
    "\n",
    "# This checks for the lowest image size in the first and second dimension\n",
    "for image in train_data:\n",
    "    count+=1\n",
    "    sum_1 += image.shape[0]\n",
    "    sum_2 += image.shape[1]\n",
    "    if image.shape[0] < value_1:\n",
    "        \n",
    "        value_1 = image.shape[0]\n",
    "        hold_1 = image.shape\n",
    "    if image.shape[1] < value_2:\n",
    "        \n",
    "        value_2 = image.shape[0]\n",
    "        hold_2 = image.shape\n",
    "        \n",
    "sum_11 = sum_1 / count\n",
    "sum_22 = sum_2 / count\n",
    "\n",
    "print(f'Average dimensions: {sum_11}, {sum_22}')\n",
    "\n",
    "plt.imshow(train_data[0], cmap = 'gray')\n",
    "\n",
    "print(f'Lowest first dimension image {hold_1}')\n",
    "print(f'Lowest second dimension image {hold_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798de0f3",
   "metadata": {},
   "source": [
    "## Resizing Function\n",
    "\n",
    "In the cell below, we define a function that resizes a given image to a dimension given the optimal manner of up- or downscaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1a2aa4",
   "metadata": {
    "id": "ff1a2aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWfUlEQVR4nO3dfYwdV3nH8e/jl8SJ7cRee22s2PESYaWgEBy0MoFUyMQEuTTC5Y9UIFGsKJKRoFVQqbDTSpWoVClVJUSRqkpWIViCQiMgdRQhwGyxqkooyabkFWNMUzsxdrxrK45fQpzYefrHjidnTnZm58593T2/j2Tdc+/cl2ev99k5Z86ZZ8zdEZG5b16/AxCR3lCyiyRCyS6SCCW7SCKU7CKJULKLJKKtZDezrWZ20Mx+a2a7OhWUiHSeNZ1nN7P5wG+AO4CjwOPAp939V50LT0Q6ZUEbr90E/Nbdnwcws+8B24DSZF+5cqWPjIy08ZEiUuXw4cOcPHnSptvWTrJfB7wY3D8KfKDqBSMjI4yPj7fxkSJSZXR0tHRbO2P26f56vG1MYGY7zGzczMYnJyfb+DgRaUc7yX4UWBfcXwsci5/k7rvdfdTdR4eHh9v4OBFpRzvJ/jiwwczeaWZXAJ8CHu5MWCLSaY3H7O5+0cz+HPgJMB/4prs/17HIRKSj2jlAh7v/CPhRh2IRkS7SCjqRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEtFWpZi4KL5phNm35bZFZSXt2kUQo2UUSkUw3vuyadnFX/c0338zb8+fP72pMIq1oel3Gy7RnF0mEkl0kEUp2kUTM2TF71fgmHKfHzwvH6VXvEW6bN09/M6X72p0KnvG31My+aWYTZvZs8NiQme0zs0PZ7fK2ohCRrquzS/oWsDV6bBcw5u4bgLHsvogMsBm78e7+X2Y2Ej28DdictfcA+4GdnQysXVVdnnB67cKFC4VtV155Za33V9ddZpumv7Gr3f04QHa7qnMhiUg3dH33ZGY7zGzczMYnJye7/XEiUqJpsp8wszUA2e1E2RPdfbe7j7r76PDwcMOP655Lly4V/p07dy7/N2/evNJ/7l76T2QQNU32h4HtWXs7sLcz4YhIt9SZevsu8AvgRjM7amb3APcDd5jZIeCO7L6IDLA6R+M/XbJpS4djEZEumrMr6GJlK97iqbazZ8/m7d///veFbYsWLepSdCLdp8likUQo2UUSkUw3PhR26RcuXFjYtnjx4rwdrwtYsmRJ3r7mmmvytlbTpaPuCVaDSL+lIolQsoskQskukohkxuzheCo86y0eZ11xxRV5e8GC4tfz0ksv5e033ngjbw8NDRWep0KVMoi0ZxdJhJJdJBHJdONDVVNlYbd+xYoVhW3hirrTp0/n7Xhl3dKlSxvFFU7rqMZdd8VTaJcuXSrdFt6Ph3aDPt0W0m+RSCKU7CKJSLIbX/dKrfHqurVr1+bt48eP5+14pV14pP7aa68tbKs7hAhnDMIuJuhofydUddWrzOYh1eyNXERaomQXSYSSXSQRc3bMXjUmqzvuit8jHMOvXLkybx85cqTwvPD++vXrC9vC1XZV48QwxqqfJRzbw9wdz1cdZ6n6PspeF79H+L3N5nF5lbn5U4nI2yjZRRIxZ7vxsbIptnCaDIpd9appuauvvjpvx92+sOt48eLF2jGVraCrimM2reBqVZMa/PE0Zfj9hyc5xf9nVd9j3f+LQac9u0gilOwiiVCyiyRizo7Z616yuWqqqu4y1euvv75w/3e/+13ePnXqVGHbq6++mrfjs+rCs+XKxu8wd6eG6oq/j/D/Oj4rLbxfNfWWgjqXf1pnZj83swNm9pyZ3Zs9PmRm+8zsUHa7vPvhikhTdXYRF4Evufu7gVuBL5jZe4BdwJi7bwDGsvsiMqDqXOvtOHA8a581swPAdcA2YHP2tD3AfmBnV6LsgLJucVU3vu5Q4KqrripsW7VqVd4+efJkYduJEyfy9pkzZwrbbrzxxrwdXpaq6Rlas0Gnf5amQ5zw/7OVabnZpKVvxsxGgFuAR4HV2R+Cy38QVlW8VET6rHaym9kS4AfAF939zEzPD163w8zGzWw8Pu9bRHqnVrKb2UKmEv077v7D7OETZrYm274GmJjute6+291H3X10eHi4EzGLSAMzjtltasDyDeCAu3812PQwsB24P7vd25UIu6DuuK5qOWu4LR53hteBu3DhQmFb2Lt5+eWXC9vCuvTh2XJ14xhUTcflTX62ptdia3omZF2D8P9UZ579NuDPgGfM7Mnssb9mKskfNLN7gBeAu7oSoYh0RJ2j8f8NlP1Z2tLZcESkW+bsCrqm6hZJqNuVDotcALz22mt5+9ixY4Vt4VTcK6+8krfjopVlMc0Uy1xR9TM3/fln29CoibTXXYokRMkukohkuvFVR8/L1O0uVq1wi7uE69aty9thMQUoduvDI/Px+y9btqxWzFUx1l0dGKoq0hErq4HfSo28uvXjOiEsYhL/XOG2eLXkbDq5Rnt2kUQo2UUSoWQXSUQyY/YmUyt1x7l1ixXGzw3PjoNioYWjR4/m7RdffLHwvCVLlkz7mvj9m0wjQvlqsqrLHFeNxatq4JeN7aviiIVFJcMpSyheZjuMMT5eEm6Lv9OqIqRNfif6RXt2kUQo2UUSkUw3vq5OT6W0chJLeALNmjVr8nbcRY67mXU++6mnnipsu+666/J2vMovFHbV4y54GEfTE1BC58+fL9wPTyIKp7/i9wu7+3HdwLLnxZfjXrx48bTPm+7zZivt2UUSoWQXSYSSXSQRyYzZOzHuajJ9F08nVb0uHAPXHUeHNerj1+3fvz9vP/bYY4Xnfe5znyt9/1B4vKCVcXk4xg5r5cfHH06fPp234+8qXppaJrzuXtVy1qr4q6YOw58lHuvPJtqziyRCyS6SiGS68XXPdKt7eeSm71f3/atWlj3//PN5+6GHHips27v3rVKAYRc5ruz79NNP5+277767sG3Tpk15OxxaxF3YsHsbr1y74YYb8na4wi2eGgtXA4btWN0p0Va+71DVEK3uVOeg055dJBFKdpFEzI3+SR90Y1VVWVcyLjn9+c9/Pm9PTBTL9YcFMOLLS4V+9rOf5e33vve9hW0f+tCH8nZ4pdnwqDoUTzIJV//FhoaGSreFP3PViS9h97+qq141vGpaZ04r6ERkVlGyiyRCyS6SiGTG7J0Yd4VTYFVTQWXPm0k4pgxXxo2NjRWe98wzz+Tt+Eyx8LPDcW7VlFc49p7u/mWLFi0q3K9a4Rb+LFUFJ+sWrwhfFz+vatxfFsdcPbOtyox7djNbZGaPmdlTZvacmX0le3zIzPaZ2aHsdnn3wxWRpup04y8At7v7+4CNwFYzuxXYBYy5+wZgLLsvIgOqzrXeHDiX3V2Y/XNgG7A5e3wPsB/Y2fEI+yju+pZ1z+MVVmHRhddff72wLez6xnXQwvcMV6c98MADheedO3cub8dd7rITOuLHN2zYkLc/+clPFratXbt22veoWxMOit3nqpNMqrrWZc9rukqubs36uXpJrbrXZ5+fXcF1Atjn7o8Cq939OEB2u6riLUSkz2olu7tfcveNwFpgk5ndVPcDzGyHmY2b2Xi8PltEeqelqTd3P81Ud30rcMLM1gBktxMlr9nt7qPuPjo8PNxetCLS2IxjdjMbBt5w99NmdhXwUeAfgIeB7cD92e3e8nd5u6pxUd0iCVXXWKsa/4VnYZ06daqw7ezZs3k7LEIIxbF4OG4Ox7/xe8Rj9nCcfvjw4cK28Cy18DLNd955Z+F5Bw4cyNvxdFjZVFZ8fbivf/3reTs8yy1Wt/Z803F03eMArRwvaBJHu6+ZDerMs68B9pjZfKZ6Ag+6+yNm9gvgQTO7B3gBuKuLcYpIm+ocjX8auGWax08BW7oRlIh0Xs9X0F2ezqqaBomnvMKpraou+JVXXpm34y54Wff8xIkTheeNjIzk7apiCuHr4hVd8WWdyqxfv770s0NxcYmDBw9OGwcUp/bC6bvPfvazhefddFP5Mda6KwDnand3rtLaeJFEKNlFEtHzbvzl7nt8lDqsbxavSAtXiYVHxMMSwlDswsbvUVZA4eabb64TNlDs3oaXZ4rVnU2oe3Q7Lgyxc+dbCxWPHDlS2LZly1uHUcITZuJpz/gofqjuke+mxSCkP7RnF0mEkl0kEUp2kUT0fMx+edwbn/E13XMuC6fUqsaa4RiyanVdOLUX10IPp/bisWvZWLaVyyLVHedWxfiud71r2nYsnAKMj1mExSjj/4vwWEgnVsnJYNCeXSQRSnaRRPS8G3+5K1x1ddMmUz/x66q61mG3OF6tF75HVRzh6rR4mq+qrlqVsoIP8c8STluGQ5z488KuezwUOHnyZN5evrxYUSye0iyLQ9342UV7dpFEKNlFEqFkF0lE3+rGtzIlVTal1kpBg7LxZSvXDQun5cJxelW8VXXMY3V/nnicXiYcp8eFKcMz/6rqxlfVhpfZRXt2kUQo2UUS0bfiFXVXp0H1mWKhcNop7i6XFcuo6mbH7xF2i8susxR/Viur68riaGWKK6yNF06hxd3xV155JW/HBTDCFXXqxs8d2rOLJELJLpKIvhWviFWtNCvrxletoKvStGtddqmipmWOq1akNSmtDW8vdFEmLAIS1+sLZxrCIUqKVz6dS7RnF0mEkl0kEUp2kUT0bQVdrMm4t+mYse7rul2soWkcdYXj8njV3dKlS/N2eAYfwLFjx/J2uGqwbj38bphtxS1bOUOw7JhMp3/O2hmWXbb5l2b2SHZ/yMz2mdmh7Hb5TO8hIv3Tyu70XuBAcH8XMObuG4Cx7L6IDKha3XgzWwv8MfD3wF9mD28DNmftPUxdynln/Frpn3CqMJ7aDAtbxN3IsLBF1WW6mnStq6YRY3VXTg6iQYy37p79a8CXgfA3ZrW7HwfIbvs3oBORGc2Y7GZ2JzDh7k80+QAz22Fm42Y2Pjk52eQtRKQD6uzZbwM+YWaHge8Bt5vZt4ETZrYGILudmO7F7r7b3UfdfTS+BJGI9E6d67PfB9wHYGabgb9y98+Y2T8C24H7s9u93QtT6grHxOEZa1Vj5bjA5Dve8Y68HZ4BV3dJc5UmU1CDrMm0WdPl2u1qZ1HN/cAdZnYIuCO7LyIDqqVFNe6+n6mj7rj7KWBL1fNFZHAMzAo66YwmXeGqAhXnz5/P23GRjiVLltT63KZd/F6tLGtH3bMT634/3ezia228SCKU7CKJUDd+jim7BFYrXcDwCHx4qam4G9+k/HcrcdTt3g6Kqnjrfgfd/Jm1ZxdJhJJdJBFKdpFEaMyeiHj1W9XlrcMz3cLx+6lTpwrPC1+3bNmywrYmZ8HVHcv2U9MptKoz+AaueIWIzG5KdpFEqBs/x5R1i5tO44TTbeE0HMCZM2fydlyvvkkN/Nkg7lqHw6Om3e7wew3rAYYrFDtBe3aRRCjZRRKhZBdJhMbsc0zZuLHuJbFjYWGLsNY8FM+Ie+211wrbys6kqzvtFBvUuvFlsbRyzYFwW9WUqM56E5FalOwiiVA3fo7pRE20sm5lPBUUPi9eodekYEUrq84GRd1ufJVwlWLY7jTt2UUSoWQXSYS68XNMJ1arlR35XrRoUeF54eq68IqxULxq7MKFC0tjqtuNl/Zpzy6SCCW7SCKU7CKJ0JhdGhdTCItchKvpABYseOtX69prry397PCzqlb5SfvqXp/9MHAWuARcdPdRMxsC/h0YAQ4Df+ruL3cnTBFpVyt/Sj/i7hvdfTS7vwsYc/cNwFh2X0QGVDvd+G3A5qy9h6lrwO1sMx5pUyeKQ9Sd8qrqdodTcRcvXszbYfceZv+JMLNJ3T27Az81syfMbEf22Gp3Pw6Q3a7qRoAi0hl19+y3ufsxM1sF7DOzX9f9gOyPww6A66+/vkGIItIJtfbs7n4su50AHgI2ASfMbA1AdjtR8trd7j7q7qPDw8OdiVpEWjbjnt3MFgPz3P1s1v4Y8HfAw8B24P7sdm83A5V6ejmeDcffixcvLmx79dVX8/bp06fz9ooVKwrPq4q3E8Uc5S11uvGrgYeyL3sB8G/u/mMzexx40MzuAV4A7upemCLSrhmT3d2fB943zeOngC3dCEpEOk8r6BJV9zJGVcIVdFV145uaDcUrZhOtTxRJhJJdJBFKdpFEaMw+x3T6Esh1x/bxMthwDB++R1U1mqqilVou2z7t2UUSoWQXSYS68XNMp7u4Teq/w9u79Ze1MuWn7npnac8ukgglu0gi1I2XnurEDIE0oz27SCKU7CKJULKLJELJLpIIJbtIIpTsIolQsoskQskukgglu0gilOwiiVCyiyRCyS6SCCW7SCKU7CKJqJXsZrbMzL5vZr82swNm9kEzGzKzfWZ2KLtd3u1gRaS5unv2fwJ+7O5/wNSloA4Au4Axd98AjGX3RWRAzZjsZnYN8GHgGwDu/rq7nwa2AXuyp+0B/qQ7IYpIJ9TZs98ATAIPmNkvzexfs0s3r3b34wDZ7aouxikibaqT7AuA9wP/4u63AOdpoctuZjvMbNzMxicnJxuGKSLtqpPsR4Gj7v5odv/7TCX/CTNbA5DdTkz3Ynff7e6j7j46PDzciZhFpIEZk93dXwJeNLMbs4e2AL8CHga2Z49tB/Z2JUIR6Yi61WX/AviOmV0BPA/czdQfigfN7B7gBeCu7oQoIp1QK9nd/UlgdJpNWzoajYh0jVbQiSRCyS6SCCW7SCKU7CKJULKLJELJLpIIJbtIIszde/dhZpPAEWAlcLJnH1xOcRQpjqJBiKPVGNa7+7Tr0nua7PmHmo27+3SLdBSH4lAcXYpB3XiRRCjZRRLRr2Tf3afPjSmOIsVRNAhxdCyGvozZRaT31I0XSURPk93MtprZQTP7rZn1rBqtmX3TzCbM7NngsZ6XwjazdWb286wc93Nmdm8/YjGzRWb2mJk9lcXxlX7EEcQzP6tv+Ei/4jCzw2b2jJk9aWbjfYyja2Xbe5bsZjYf+Gfgj4D3AJ82s/f06OO/BWyNHutHKeyLwJfc/d3ArcAXsu+g17FcAG539/cBG4GtZnZrH+K47F6mypNf1q84PuLuG4Oprn7E0b2y7e7ek3/AB4GfBPfvA+7r4eePAM8G9w8Ca7L2GuBgr2IJYtgL3NHPWICrgf8BPtCPOIC12S/w7cAj/fq/AQ4DK6PHehoHcA3wf2TH0jodRy+78dcBLwb3j2aP9UtfS2Gb2QhwC/BoP2LJus5PMlUodJ9PFRTtx3fyNeDLwJvBY/2Iw4GfmtkTZrajT3F0tWx7L5PdpnksyakAM1sC/AD4oruf6UcM7n7J3TcytWfdZGY39ToGM7sTmHD3J3r92dO4zd3fz9Qw8wtm9uE+xNBW2faZ9DLZjwLrgvtrgWM9/PxYrVLYnWZmC5lK9O+4+w/7GQuAT13dZz9TxzR6HcdtwCfM7DDwPeB2M/t2H+LA3Y9ltxPAQ8CmPsTRVtn2mfQy2R8HNpjZO7MqtZ9iqhx1v/S8FLaZGVOX0Trg7l/tVyxmNmxmy7L2VcBHgV/3Og53v8/d17r7CFO/D//p7p/pdRxmttjMll5uAx8Dnu11HN7tsu3dPvARHWj4OPAb4H+Bv+nh534XOA68wdRfz3uAFUwdGDqU3Q71II4/ZGro8jTwZPbv472OBbgZ+GUWx7PA32aP9/w7CWLazFsH6Hr9fdwAPJX9e+7y72affkc2AuPZ/81/AMs7FYdW0IkkQivoRBKhZBdJhJJdJBFKdpFEKNlFEqFkF0mEkl0kEUp2kUT8P6UD+ndjYE5WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resizer(image, target_dimension):\n",
    "    '''\n",
    "    Takes an image and a desired dimension (tuple), and converts the image given the best interpolation method\n",
    "    '''\n",
    "\n",
    "    if len(image[0]) * len(image[1]) > target_dimension[0] * target_dimension[1]:\n",
    "        rescaled_image = np.expand_dims(cv2.resize(image, dsize = target_dimension, interpolation = cv2.INTER_AREA), axis = 2) \n",
    "    else:\n",
    "        rescaled_image = np.expand_dims(cv2.resize(image, dsize = target_dimension, interpolation = cv2.INTER_CUBIC), axis = 2)        \n",
    "    return rescaled_image    \n",
    "    \n",
    "# Create an empty list for the training data\n",
    "train_data_resized = []\n",
    "target_dim = (64, 64)\n",
    "\n",
    "# Loop through the images in the training data and resize them to desired dimension\n",
    "for image in train_data:\n",
    "    train_data_resized.append(resizer(image, target_dim))\n",
    "\n",
    "# Test if the image is resized and show the image\n",
    "print(train_data_resized[0].shape)\n",
    "plt.imshow(train_data_resized[0], cmap = 'gray')\n",
    "\n",
    "#Split the data into 70% training and 30% validation\n",
    "im_train, im_val, lab_train, lab_val = train_test_split(train_data_resized, train_labels, train_size=0.7, random_state=1265599650, stratify = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cddaa21",
   "metadata": {
    "id": "9cddaa21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21235, 64, 64, 1)\n",
      "(21235, 121)\n",
      "(9101, 64, 64, 1)\n",
      "(9101, 121)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to numpy arrays, so tensorflow can use them\n",
    "image_train = np.array(im_train)\n",
    "label_train = np.array(lab_train)\n",
    "image_val = np.array(im_val)\n",
    "label_val = np.array(lab_val)\n",
    "\n",
    "# Test if the shapes are correct\n",
    "print(image_train.shape)\n",
    "print(label_train.shape)\n",
    "print(image_val.shape)\n",
    "print(label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024880",
   "metadata": {
    "id": "15024880"
   },
   "source": [
    "## Convolutional network\n",
    "\n",
    "We use the function 'train_and_evaluate' which, obviously, trains our model and then evaluates the trained model on the validation data. This function was reused from the CIFAR-assignment from module 6 of ML2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce50c7",
   "metadata": {
    "id": "e2ce50c7"
   },
   "source": [
    "Y_ints line: https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b49593d",
   "metadata": {
    "id": "3b49593d"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_x, train_y, val_x, val_y, preprocess={}, epochs=20, augment={}, decay = True, \n",
    "                       initial_learning_rate = 1e-5, learning_rate = 0.00009):\n",
    "    \n",
    "    if decay:\n",
    "        print(\"Learning rate decay is ON\")\n",
    "        \n",
    "        \n",
    "        # Define a learning rate schedule\n",
    "        optimizer = tf.keras.optimizers.SGD(lr=initial_learning_rate, momentum= 0.9, decay= initial_learning_rate/epochs, nesterov=False)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(lr = learning_rate)\n",
    "        print(f\"Learning rate decay is OFF. Learning rate is {learning_rate}\")\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
    "    train_gen.fit(train_x) \n",
    "\n",
    "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
    "    val_gen.fit(train_x)\n",
    "    \n",
    "    # used for k-fold\n",
    "    y_ints = [y.argmax() for y in label_train]\n",
    "    class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_ints), y = y_ints)\n",
    "    \n",
    "    history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n",
    "                        validation_data=val_gen.flow(val_x, val_y))\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
    "\n",
    "    for i, metric in enumerate(['loss', 'accuracy']):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].plot(history.history['val_'+metric])\n",
    "        axs[i].legend(['training', 'validation'], loc='best')\n",
    "\n",
    "        axs[i].set_title('Model '+metric)\n",
    "        axs[i].set_ylabel(metric)\n",
    "        axs[i].set_xlabel('epoch')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Validation Accuracy: {model.evaluate(val_gen.flow(val_x, val_y))[1]}\")\n",
    "    return model.evaluate(val_gen.flow(val_x, val_y))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2820be",
   "metadata": {
    "id": "3c2820be"
   },
   "source": [
    "## The actual model\n",
    "\n",
    "We start with a very simple convolutional neural network, with 2 convolutional layers, both with pooling afterwards, and one dense layer. kernelsize, amount of filters, amount of nodes are specified in the code cell. This first version of the model gives us a validation accuracy of approximately 64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a184d5",
   "metadata": {
    "id": "74a184d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate decay is ON\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inital_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6336/2722673180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6336/1347199347.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_x, train_y, val_x, val_y, preprocess, epochs, augment, decay, initial_learning_rate, learning_rate)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Define a learning rate schedule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minital_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minitial_learning_rate\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inital_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "def build_model(first_layer_filters = 32, second_layer_filters = 64, third_layer_filters = 128,fourth_layer_filters = 128, \n",
    "                kernelsize = (3,3), inputshape = (64, 64, 1), first_hidden_layer_nodes = 1024, second_hidden_layer_nodes = 512, \n",
    "                pooling_size = (2,2), activation = layers.LeakyReLU(alpha= 0.15)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that builds a sequential model with the given architecture\n",
    "    \"\"\"\n",
    "    output_nodes = 121\n",
    "    \n",
    "    model_1 = models.Sequential()\n",
    "\n",
    "    model_1.add(layers.Conv2D(first_layer_filters, kernelsize, activation = activation, padding = 'same', input_shape = inputshape))\n",
    "    model_1.add(layers.Conv2D(first_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D(pooling_size))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model_1.add(layers.Conv2D(second_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(second_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D(pooling_size))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model_1.add(layers.Conv2D(third_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(third_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D(pooling_size))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model_1.add(layers.Conv2D(fourth_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(fourth_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D(pooling_size))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model_1.add(layers.Flatten())\n",
    "\n",
    "    model_1.add(layers.Dense(first_hidden_layer_nodes, activation = activation))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    model_1.add(layers.Dense(second_hidden_layer_nodes, activation = activation))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    model_1.add(layers.Dense(output_nodes, activation = 'softmax'))\n",
    "    \n",
    "    return model_1\n",
    "\n",
    "model_1 = build_model()\n",
    "\n",
    "train_and_evaluate(model_1, image_train, label_train, image_val, label_val, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ace847",
   "metadata": {
    "id": "f8ace847"
   },
   "outputs": [],
   "source": [
    "model_1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1FV_kXH6EZA_",
   "metadata": {
    "id": "1FV_kXH6EZA_"
   },
   "source": [
    "## Different resizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed76964",
   "metadata": {
    "id": "6ed76964"
   },
   "outputs": [],
   "source": [
    "# Filter out the largest example (and possibily the second-largest) to illustrate resizing\n",
    "storage_1 = 0 \n",
    "storage_2 = 0\n",
    "store_img1 = None\n",
    "store_img2 = None\n",
    "for image in train_data:\n",
    "    store = image.shape[0]\n",
    "    if store > storage_1 and store > storage_2:\n",
    "        store_img1 = image\n",
    "        storage_1 = image.shape[0]\n",
    "    if store > storage_2 and store != storage_1:\n",
    "        store_img2 = image\n",
    "        storage_2 = image.shape[0]\n",
    "        \n",
    "\n",
    "# Plot the different manners of interpolation for comparison\n",
    "f, axarr = plt.subplots(2,3, figsize=(12, 12))\n",
    "axarr[0,0].imshow(store_img1, cmap = 'gray')\n",
    "axarr[0,0].set_title('Original picture:')\n",
    "axarr[1,0].imshow(cv2.resize(store_img1, dsize = (32, 32), interpolation = cv2.INTER_LINEAR), cmap = 'gray')\n",
    "axarr[1,0].set_title('Bilinear interpolation:')\n",
    "axarr[0,1].imshow(cv2.resize(store_img1, dsize = (32, 32), interpolation = cv2.INTER_AREA), cmap = 'gray')\n",
    "axarr[0,1].set_title('Pixel area relation interpolation:')\n",
    "axarr[1,1].imshow(cv2.resize(store_img1, dsize = (32, 32), interpolation = cv2.INTER_NEAREST), cmap = 'gray')\n",
    "axarr[1,1].set_title('Nearest-neighbor interpolation:')\n",
    "axarr[0,2].imshow(cv2.resize(store_img1, dsize = (32, 32), interpolation = cv2.INTER_CUBIC), cmap = 'gray')\n",
    "axarr[0,2].set_title('Bicubic interpolation:')\n",
    "axarr[1,2].imshow(cv2.resize(store_img1, dsize = (32, 32), interpolation = cv2.INTER_LANCZOS4), cmap = 'gray')\n",
    "axarr[1,2].set_title('Lanczos interpolation:')\n",
    "\n",
    "#plt.savefig('resizingmethods.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cebbf9",
   "metadata": {
    "id": "c6cebbf9"
   },
   "outputs": [],
   "source": [
    "# First compute the predictions based on the trained model\n",
    "y_pred = tf.keras.utils.to_categorical(model_1.predict_classes(image_val))\n",
    "\n",
    "\n",
    "# Convert both actual and predict to utilize in conf matrix \n",
    "y_true = tf.argmax(label_val, axis=1)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute matrix\n",
    "conf_matrix = tfmath.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Remove the diagonal for clearer image\n",
    "cnf_mtrx = np.array(conf_matrix)\n",
    "np.fill_diagonal(cnf_mtrx, 0)\n",
    "\n",
    "# Save this version for usage with SMOTE\n",
    "smote_conf_matr = np.copy(cnf_mtrx)\n",
    "\n",
    "# Compute heatmap for abosulte numbers\n",
    "\n",
    "plt.figure(figsize=(60,60))\n",
    "ax = sns.heatmap(cnf_mtrx, annot=True, fmt=\"d\", xticklabels=categories_list, yticklabels=categories_list)\n",
    "ax.set(xlabel='Predicted Class', ylabel='Actual Class')\n",
    "plt.show()\n",
    "\n",
    "# Compute the relative (%) cf matrix and corresponding heatmap\n",
    "\n",
    "cnf_mtrx = np.nan_to_num((cnf_mtrx / cnf_mtrx.astype(np.float).sum()), copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "plt.figure(figsize=(60,60))\n",
    "ax = sns.heatmap(cnf_mtrx, annot=True, xticklabels=categories_list, yticklabels=categories_list)\n",
    "ax.set(xlabel='Predicted Class', ylabel='Actual Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e73cd",
   "metadata": {},
   "source": [
    "## Stratified K-folds\n",
    "\n",
    "In the cell below, we can train the model in K stratified folds, meaning we can test the model over different test and train splits that take the distribution of classes into account when making said splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to array before split to use in stratified kfolds\n",
    "all_image = np.array(train_data_resized)\n",
    "all_labels = np.array(train_labels)\n",
    "\n",
    "# Convert one hot matrix back to label vector\n",
    "y_ints_all = [y.argmax() for y in all_labels]\n",
    "y_ints_all = np.array(y_ints_all)\n",
    "\n",
    "\n",
    "def stratified_kfold(n_splits = 2):\n",
    "    \"\"\"\n",
    "    Function that trains and evaluates the model on K stratified train test splits\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define stratified kfold and number of splits\n",
    "    skf = StratifiedKFold(n_splits = n_splits)\n",
    "    skf.get_n_splits(all_image, all_labels)\n",
    "\n",
    "    val_accuracy_list = []\n",
    "\n",
    "    # Iterate over the splits\n",
    "    for train_index, test_index in skf.split(all_image, y_ints_all):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = all_image[train_index], all_image[test_index]\n",
    "        y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "        model_1 = build_model()\n",
    "\n",
    "        # Call train and evaluate for every split\n",
    "        val_accuracy = train_and_evaluate(model_1, X_train, y_train, X_test, y_test, epochs = 10)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "    \n",
    "    # Print the mean accuracies\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(f\"The mean accuracy of {n_splits} folds is {np.mean(val_accuracy_list)}\")\n",
    "\n",
    "stratified_kfold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317948f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2573ce",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "In the cell below, we oversample the minority classes in the training data to try and combat the data imbalance. We can try and adjust the parameters of the smote to set a limit to which classes get oversampled. This is important as it may be ineffective to oversample the smallest classes. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa740bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smote_conf_matr)\n",
    "def conf_smote_dict(smote_conf_matr, min_errors, smote_value, max_smote_value = 1385, min_smote_value = 400):\n",
    "    smote_dict = {}\n",
    "    j = 0\n",
    "    for pred in smote_conf_matr:\n",
    "        error_classes = list(np.where(pred >= min_errors)[0])\n",
    "        error_values = pred[pred>= min_errors]\n",
    "        if len(error_classes) > 0:\n",
    "                actual_class = j\n",
    "                smote_dict[actual_class] = np.clip(sum(error_values) * 2, min_smote_value, max_smote_value)\n",
    "        for i in range(len(error_classes)):\n",
    "            smote_dict[error_classes[i]] = np.clip(error_values[i] * 4, min_smote_value, max_smote_value)\n",
    "        j += 1\n",
    "    return smote_dict\n",
    "\n",
    "conf_smote_dict = conf_smote_dict(smote_conf_matr, 100, 800)\n",
    "print(conf_smote_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15105815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_dict(class_size_list, label_train, smote_size = 1385, smallest_oversample = 45):\n",
    "    one_hot_list = np.unique(label_train, axis = 0)\n",
    "    int_list = [y.argmax() for y in one_hot_list]\n",
    "    smote_dict = {}\n",
    "    \n",
    "    for i in range(len(int_list)):\n",
    "        if class_size_list[i] > smallest_oversample:\n",
    "            smote_dict[int_list[i]] = smote_size\n",
    "        \n",
    "    return smote_dict\n",
    "\n",
    "smote_dict = smote_dict(class_size_list, label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(image_train, smote_dict, k = 4):\n",
    "    \"\"\"\n",
    "    Function that oversamples the minority classes of the given data based on K neighbors\n",
    "    \"\"\"\n",
    "    # Convert labels into ints\n",
    "    y_ints = [y.argmax() for y in label_train]\n",
    "    \n",
    "    # Get shape of the train data\n",
    "    nsamples, nx, ny, nz = image_train.shape\n",
    "\n",
    "    # Create two dimensional traindata\n",
    "    d2_train_dataset = image_train.reshape((nsamples, nx * ny * nz))\n",
    "\n",
    "    # Define smote for minority classes\n",
    "    smote = SMOTE(sampling_strategy = smote_dict, k_neighbors = k)\n",
    "\n",
    "    # Apply smote to our 2 dim traning data\n",
    "    X_smote, y_smote = smote.fit_resample(d2_train_dataset , y_ints)\n",
    "\n",
    "    # Convert labels back to one hot\n",
    "    y_smote = tf.keras.utils.to_categorical(y_smote, num_classes=121)\n",
    "    \n",
    "    # Print the new shape to see how this affected the data\n",
    "    print(f\"The shape of X after smote is: {X_smote.shape}, the shape of y after smote is: {y_smote.shape}\")\n",
    "\n",
    "    # Reshape the smote data into the original format\n",
    "    smoted_train = X_smote.reshape((X_smote.shape[0], nx, ny, nz))\n",
    "\n",
    "    # Check the shapes\n",
    "    print(f\"The shape of X after smote and reshaping is {smoted_train.shape}\")\n",
    "    \n",
    "    return smoted_train, y_smote\n",
    "\n",
    "smoted_train, y_smote = smote_data(image_train, smote_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3a1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "def decayed_learning_rate(step, initial_learning_rate = 0.001, decay_rate = 1, decay_steps = 10000):\n",
    "  return initial_learning_rate * decay_rate ** (step / decay_steps)\n",
    "\n",
    "print(decayed_learning_rate(100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plankton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
