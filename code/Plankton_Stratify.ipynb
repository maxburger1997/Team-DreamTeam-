{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a4f57f",
   "metadata": {
    "id": "e2a4f57f"
   },
   "source": [
    "# Machine Learning Project 2022: Plankton\n",
    "\n",
    "### Authors:\n",
    "- Bram Fresen\n",
    "- Bram Huis\n",
    "- Max Burger\n",
    "- Moos Middelkoop\n",
    "\n",
    "For the Machine Learning Project to finish off the minor Artificial Intelligence, we chose to tackle the plankton problem, originally uploaded as the United States national data science bowl in december 2014. For this problem, the goal is to classify microscopic images of particles in water as one of 121 different classes of plankton. The dataset is 30.000 images large, with varying sizes. The dataset is also imbalanced.\n",
    "\n",
    "In order to solve this problem we will make use of a Convolutional Neural Network using the tensorflow library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144121",
   "metadata": {
    "id": "fb144121"
   },
   "source": [
    "## Import libraries\n",
    "\n",
    "Firstly, we will import the needed libraries, and check if we are running on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc8cd45",
   "metadata": {
    "id": "ccc8cd45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from tensorflow import math as tfmath\n",
    "\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80ec50",
   "metadata": {
    "id": "0d80ec50"
   },
   "source": [
    "## Loading the training data and training labels\n",
    "\n",
    "We use the cv2 library to load the training images (which are .jpg files), and turn them into arrays. This piece of code was found online:\n",
    "\n",
    "https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "https://drive.google.com/file/d/1hAaPzDMVEZ8X1tfRS2ieFEqi0R7Ww7uL/view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851be41",
   "metadata": {
    "id": "c851be41"
   },
   "source": [
    "### Training data\n",
    "\n",
    "Training data is sorted into folders by class, this next piece of code reads in the training data, puts it in an array, and constructs an array for the classes by using the names of the folders. At the end, this array for the labels is turned into a one-hot matrix, so that tensorflow can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024ae544",
   "metadata": {
    "id": "024ae544"
   },
   "outputs": [],
   "source": [
    "def read_data(folder):\n",
    "    # Create empty lists for the not resized training data, the labels (not one hot encoded yet) and the class sizes\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    class_size_list = []\n",
    "    categories_list =[]\n",
    "    offset = 0\n",
    "\n",
    "    # Loop through the index (for the one hot matrix) and the categories\n",
    "    for number, categories in enumerate(os.listdir(folder)):\n",
    "        class_size = 0\n",
    "        categories_list.append(categories)\n",
    "        \n",
    "\n",
    "        # If we come across a hidden folder (starting with \".\") on mac os, we ignore it\n",
    "        if categories[0] == \".\":\n",
    "            offset += 1\n",
    "            continue\n",
    "\n",
    "        # Loop through the images , add 1 to the class size, read the images in in and add them to a list, \n",
    "        # also add the index 'number' to a list for the one hot matrix\n",
    "        for image in os.listdir(f'{folder}/{categories}'):\n",
    "            class_size += 1\n",
    "            train_labels.append(number - offset)\n",
    "            img = cv2.imread(os.path.join(f'{folder}/{categories}', image))\n",
    "            train_data.append(img[:, :, 0])\n",
    "      \n",
    "        # Append the size of the class to the class size list, in order to check the class sizes later, this way we\n",
    "        # can ananlyze the degree of class imbalance\n",
    "        class_size_list.append(class_size)\n",
    "\n",
    "    # Create a one hot matrix from the train labels\n",
    "    train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=121)\n",
    "  \n",
    "    return train_data, train_labels_one_hot, class_size_list, categories_list\n",
    "\n",
    "train_data, train_labels, class_size_list, categories_list = read_data('data/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1615b0",
   "metadata": {
    "id": "bb1615b0"
   },
   "source": [
    "Analyzing degree of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6deaa34b",
   "metadata": {
    "id": "6deaa34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[889, 13, 71, 49, 16, 532, 242, 696, 393, 170, 815, 1934, 694, 77, 681, 173, 96, 178, 63, 286, 106, 49, 87, 30, 899, 1189, 24, 201, 113, 42, 53, 38, 55, 363, 394, 914, 519, 500, 36, 92, 80, 88, 385, 536, 96, 27, 14, 136, 38, 511, 10, 31, 85, 114, 64, 16, 10, 127, 75, 35, 229, 9, 19, 132, 23, 336, 12, 190, 412, 274, 150, 76, 703, 123, 43, 56, 14, 61, 14, 24, 141, 131, 108, 372, 625, 1172, 113, 108, 13, 65, 287, 158, 52, 49, 153, 174, 212, 135, 483, 179, 57, 247, 29, 30, 128, 21, 24, 38, 708, 54, 1979, 678, 29, 439, 417, 352, 236, 73, 317, 175, 425]\n",
      "\n",
      "Biggest class: 1979\n",
      "\n",
      "Smallest class: 9\n"
     ]
    }
   ],
   "source": [
    "print(class_size_list)\n",
    "print()\n",
    "print(f'Biggest class: {max(class_size_list)}')\n",
    "print()\n",
    "print(f'Smallest class: {min(class_size_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0704a",
   "metadata": {
    "id": "89a0704a"
   },
   "source": [
    "### Deleting unnecessary channels\n",
    "\n",
    "There are 3 channels in each of the images. The cell below shows that each of the channels have the same values (test 1 and 2). Test 3 and 4 are here to show that the 'np.array_equal' function works; the values from different images return a false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b9048ef",
   "metadata": {
    "id": "2b9048ef"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11552/150489883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mb0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "x = train_data[0]\n",
    "y = train_data[1]\n",
    "\n",
    "a0 = x[:, :, 0]\n",
    "b0 = x[:, :, 1]\n",
    "c0 = x[:, :, 2]\n",
    "\n",
    "a1 = y[:, :, 0]\n",
    "b1 = y[:, :, 1]\n",
    "c1 = y[:, :, 2]\n",
    "\n",
    "test_1 = np.array_equal(a0, b0)\n",
    "test_2 = np.array_equal(b0, c0)\n",
    "\n",
    "test_3 = np.array_equal(a0, a1)\n",
    "test_4 = np.array_equal(b0, c1)\n",
    "\n",
    "\n",
    "print(f' Test 1: {test_1}, Test 2: {test_2}')\n",
    "print(f' Test 3: {test_3}, Test 4: {test_4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6cb5a",
   "metadata": {
    "id": "24d6cb5a",
    "outputId": "7552739a-b447-4b3d-ea37-22a6185e540f"
   },
   "source": [
    "We only proceed with one of the three channels, to eliminate redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "qaI7P5qy9L3Q",
   "metadata": {
    "id": "qaI7P5qy9L3Q"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11552/3023630872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m       \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(train_data):\n",
    "      train_data[i] = image[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d208c",
   "metadata": {
    "id": "1d7d208c"
   },
   "source": [
    "# Resize input images\n",
    "\n",
    "Because all images are differnt sizes, it is necessary to resize all input data to the same size, in order to make tensorflow be able to work with the data. The first cell below analyzes the sizes of the data, and the second cell actually resizes, based on this analysis. Lastly, the data is converted into numpy arrays, so tensorflow will be able to work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5838d255",
   "metadata": {
    "id": "5838d255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average dimensions: 66.66182093881856, 73.50728507383967\n",
      "Lowest first dimension image (21, 71)\n",
      "Lowest second dimension image (31, 49)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start with an infinitely large number\n",
    "value_1 = math.inf\n",
    "value_2 = math.inf\n",
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "count = 0\n",
    "\n",
    "# This checks for the lowest image size in the first and second dimension\n",
    "for image in train_data:\n",
    "    count+=1\n",
    "    sum_1 += image.shape[0]\n",
    "    sum_2 += image.shape[1]\n",
    "    if image.shape[0] < value_1:\n",
    "        \n",
    "        value_1 = image.shape[0]\n",
    "        hold_1 = image.shape\n",
    "    if image.shape[1] < value_2:\n",
    "        \n",
    "        value_2 = image.shape[0]\n",
    "        hold_2 = image.shape\n",
    "        \n",
    "sum_11 = sum_1 / count\n",
    "sum_22 = sum_2 / count\n",
    "\n",
    "print(f'Average dimensions: {sum_11}, {sum_22}')\n",
    "\n",
    "plt.imshow(train_data[0], cmap = 'gray')\n",
    "\n",
    "print(f'Lowest first dimension image {hold_1}')\n",
    "print(f'Lowest second dimension image {hold_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1a2aa4",
   "metadata": {
    "id": "ff1a2aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty list for the training data\n",
    "train_data_resized = []\n",
    "\n",
    "# Loop through the images in the training data and resize them to the lowest shape in the dataset, \n",
    "# add a third dimension of 1 to the images and then append the image to the 'train_data_resized' list\n",
    "for image in train_data:\n",
    "    img = cv2.resize(image, dsize = (32, 32), interpolation = cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis = 2)\n",
    "    train_data_resized.append(img)\n",
    "\n",
    "# Test if the image is resized and show the image\n",
    "print(train_data_resized[0].shape)\n",
    "plt.imshow(train_data_resized[0], cmap = 'gray')\n",
    "\n",
    "#Split the data into 70% training and 30% validation\n",
    "im_train, im_val, lab_train, lab_val = train_test_split(train_data_resized, train_labels, train_size=0.7, random_state=1265599650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cddaa21",
   "metadata": {
    "id": "9cddaa21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21235, 32, 32, 1)\n",
      "(21235, 121)\n",
      "(9101, 32, 32, 1)\n",
      "(9101, 121)\n"
     ]
    }
   ],
   "source": [
    "# Convert the split data to numpy arrays, so tensorflow can use them\n",
    "image_train = np.array(im_train)\n",
    "label_train = np.array(lab_train)\n",
    "image_val = np.array(im_val)\n",
    "label_val = np.array(lab_val)\n",
    "\n",
    "# Test if the shapes are correct\n",
    "print(image_train.shape)\n",
    "print(label_train.shape)\n",
    "print(image_val.shape)\n",
    "print(label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024880",
   "metadata": {
    "id": "15024880"
   },
   "source": [
    "## Convolutional network\n",
    "\n",
    "We use the function 'train_and_evaluate' which, obviously, trains our model and then evaluates the trained model on the validation data. This function was reused from the CIFAR-assignment from module 6 of ML2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce50c7",
   "metadata": {
    "id": "e2ce50c7"
   },
   "source": [
    "Y_ints line: https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b49593d",
   "metadata": {
    "id": "3b49593d"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_x, train_y, val_x, val_y, preprocess={}, epochs=20, augment={}, decay = False, \n",
    "                       initial_learning_rate = 1e-3, decay_steps = 10000, decay_rate = 0.9):\n",
    "    \n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
    "    train_gen.fit(train_x) \n",
    "\n",
    "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
    "    val_gen.fit(train_x)\n",
    "    \n",
    "   # y_ints = [y.argmax() for y in label_train]\n",
    "    #class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_ints), y = y_ints)\n",
    "    \n",
    "    history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n",
    "                        validation_data=val_gen.flow(val_x, val_y))\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
    "\n",
    "    for i, metric in enumerate(['loss', 'accuracy']):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].plot(history.history['val_'+metric])\n",
    "        axs[i].legend(['training', 'validation'], loc='best')\n",
    "\n",
    "        axs[i].set_title('Model '+metric)\n",
    "        axs[i].set_ylabel(metric)\n",
    "        axs[i].set_xlabel('epoch')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Validation Accuracy: {model.evaluate(val_gen.flow(val_x, val_y))[1]}\")\n",
    "    return model.evaluate(val_gen.flow(val_x, val_y))[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2820be",
   "metadata": {
    "id": "3c2820be"
   },
   "source": [
    "## The actual model\n",
    "\n",
    "We start with a very simple convolutional neural network, with 2 convolutional layers, both with pooling afterwards, and one dense layer. kernelsize, amount of filters, amount of nodes are specified in the code cell. This first version of the model gives us a validation accuracy of approximately 47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54f63f17",
   "metadata": {
    "id": "54f63f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay\n",
      "<keras.optimizer_v2.gradient_descent.SGD object at 0x00000180A33A5308>\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000180A3962948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000180A3962948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 43/664 [>.............................] - ETA: 52s - loss: 4.5932 - accuracy: 0.0567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14524/4268622667.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14524/4245641154.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_x, train_y, val_x, val_y, preprocess, epochs, augment, decay, initial_learning_rate, decay_steps, decay_rate)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n\u001b[1;32m---> 18\u001b[1;33m                         validation_data=val_gen.flow(val_x, val_y))\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_model(first_layer_filters = 32, second_layer_filters = 64, third_layer_filters = 128,fourth_layer_filters = 256, \n",
    "                kernelsize = (3,3), inputshape = (32, 32, 1), first_hidden_layer_nodes = 256, second_hidden_layer_nodes = 128, \n",
    "                pooling_size = (2,2), activation = layers.LeakyReLU(alpha=0.1),decay = False, \n",
    "                       initial_learning_rate = 1e-3, decay_steps = 10000, decay_rate = 0.9):\n",
    "    \n",
    "    \n",
    "    output_nodes = 121\n",
    "    # optimizer = 'adam'\n",
    "    if decay:\n",
    "        print(\"decay\")\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = initial_learning_rate,\n",
    "        decay_steps= decay_steps,\n",
    "        decay_rate = decay_rate)\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    \n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n",
    "    \n",
    "    print(optimizer)\n",
    "    model_1 = models.Sequential()\n",
    "\n",
    "    model_1.add(layers.Conv2D(first_layer_filters, kernelsize, activation = activation, padding = 'same', input_shape = inputshape))\n",
    "    model_1.add(layers.Conv2D(first_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model_1.add(layers.Conv2D(second_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(second_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model_1.add(layers.Conv2D(third_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(third_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model_1.add(layers.Conv2D(fourth_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.Conv2D(fourth_layer_filters, kernelsize, activation = activation, padding = 'same'))\n",
    "    model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model_1.add(layers.Flatten())\n",
    "\n",
    "    model_1.add(layers.Dense(first_hidden_layer_nodes, activation = activation))\n",
    "    model_1.add(layers.Dropout(0.15))\n",
    "    model_1.add(layers.Dense(second_hidden_layer_nodes, activation = activation))\n",
    "    model_1.add(layers.Dropout(0.15))\n",
    "    model_1.add(layers.Dense(output_nodes, activation = 'softmax'))\n",
    "\n",
    "    \n",
    "    return model_1\n",
    "\n",
    "model_1 = build_model(decay = True)\n",
    "\n",
    "train_and_evaluate(model_1, image_train, label_train, image_val, label_val, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4da84",
   "metadata": {
    "id": "4ea4da84"
   },
   "source": [
    "## Stratified K-folds\n",
    "\n",
    "In the cell below, we can train the model in K stratified folds, meaning we can test the model over different test and train splits that take the distribution of classes into account when making said splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "530b18ba",
   "metadata": {
    "id": "530b18ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  445   446   447 ... 30333 30334 30335] TEST: [    0     1     2 ... 30120 30121 30122]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bramm\\.conda\\envs\\progLab\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C806F8FA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C806F8FA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 25/474 [>.............................] - ETA: 33s - loss: 5.1690 - accuracy: 0.0400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11552/3327517287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"The mean accuracy of {n_splits} folds is {np.mean(val_accuracy_list)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mstratified_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11552/3327517287.py\u001b[0m in \u001b[0;36mstratified_kfold\u001b[1;34m(n_splits)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Call train and evaluate for every split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mval_accuracy_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------------------------------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11552/3674012052.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_x, train_y, val_x, val_y, preprocess, epochs, augment, decay, initial_learning_rate, decay_steps, decay_rate)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n\u001b[1;32m---> 23\u001b[1;33m                         validation_data=val_gen.flow(val_x, val_y))\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\progLab\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(lr= 0.0001)\n",
    "\n",
    "# Convert data to array before split to use in stratified kfolds\n",
    "all_image = np.array(train_data_resized)\n",
    "all_labels = np.array(train_labels)\n",
    "\n",
    "# Convert one hot matrix back to label vector\n",
    "y_ints_all = [y.argmax() for y in all_labels]\n",
    "y_ints_all = np.array(y_ints_all)\n",
    "\n",
    "\n",
    "def stratified_kfold(n_splits = 2):\n",
    "\n",
    "    # Define stratified kfold and number of splits\n",
    "    skf = StratifiedKFold(n_splits= n_splits)\n",
    "    skf.get_n_splits(all_image, all_labels)\n",
    "\n",
    "    val_accuracy_list = []\n",
    "\n",
    "    # Iterate over the splits\n",
    "    for train_index, test_index in skf.split(all_image, y_ints_all):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = all_image[train_index], all_image[test_index]\n",
    "        y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "        model_1 = build_model()\n",
    "\n",
    "        # Call train and evaluate for every split\n",
    "        val_accuracy = train_and_evaluate(model_1, X_train, y_train, X_test, y_test, epochs = 10)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(f\"The mean accuracy of {n_splits} folds is {np.mean(val_accuracy_list)}\")\n",
    "\n",
    "stratified_kfold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e0937",
   "metadata": {
    "id": "9b0e0937"
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "While we start with a rather decent accuracy compared to the at-random probability, we suspect that the relatively small classes are being 'overlooked' by our model, due to their low sample size. To investigate this suspicion, we plot the confusion matrix, to investigate whether this suspision is true or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da687c",
   "metadata": {
    "id": "00da687c"
   },
   "outputs": [],
   "source": [
    "# First compute the predictions based on the trained model\n",
    "y_pred = model_1.predict_classes(image_val)\n",
    "y_pred = tf.keras.utils.to_categorical(y_pred)\n",
    "\n",
    "# Convert both actual and predict to utilize in conf matrix \n",
    "y_true = tf.argmax(label_val, axis=1)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute matrix\n",
    "conf_matrix = tfmath.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Compute heatmap \n",
    "plt.figure(figsize=(30,3060))\n",
    "ax = sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "ax.set(xlabel='Predicted Class', ylabel='Actual Class')\n",
    "plt.show()\n",
    "\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O1GnoUtmLuRy",
   "metadata": {
    "id": "O1GnoUtmLuRy"
   },
   "source": [
    "test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWV0H51vLvSq",
   "metadata": {
    "id": "wWV0H51vLvSq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Plankton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
